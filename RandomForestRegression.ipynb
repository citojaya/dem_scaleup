{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression for predicting impact energy\n",
    "#### Ref:  https://towardsdatascience.com/random-forest-in-python-24d0893d51c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our features is: (1076, 26)\n",
      "Index(['id', 'z', 'd/mesh', 'T', 'normT', 'h', 'h/z', 'atan', 'normz', 'normh',\n",
      "       'Hardness', 'A', 'E/A', 'normE', 'finnei', 'shear', 'IESM',\n",
      "       'F_plus_IESM', 'wear_rate(mm/hr)', 'wear_rate_percentage', 'k', 'k1',\n",
      "       'averageE', 'ratio', 'const', 'const2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Pandas is used for data manipulation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Read in data and display first 5 rows\n",
    "\n",
    "def linear(m,x):\n",
    "    return m*x\n",
    "\n",
    "\n",
    "features0 = pd.read_excel('../Paper/WearPaper/time_energy_wear_rate_forK2_test2.xlsx')\n",
    "# features = pd.read_excel('../Paper/WearPaper/time_energy_wear_rate_forK2_test2.xlsx')\n",
    "\n",
    "\n",
    "# multiply\n",
    "for i in range(2):\n",
    "    features0 = features0.append(features0)\n",
    "\n",
    "features = features0\n",
    "# features.set_index('id')\n",
    "# print(features.head(5))\n",
    "\n",
    "# features = features.iloc[20:-18,:] # remove D=127 and last 18 rows\n",
    "# features = features.iloc[:100,:] # remove last 18 rows\n",
    "# f = features['N'] < 0.65\n",
    "# features = features[f]\n",
    "# features = features[(features[\"N\"] == 0.7)]\n",
    "print('The shape of our features is:', features.shape)\n",
    "\n",
    "\n",
    "# Descriptive statistics for each column\n",
    "#print(features.describe())\n",
    "\n",
    "\n",
    "# One-hot encode the data using pandas get_dummies\n",
    "# features = pd.get_dummies(features)\n",
    "# Display the first 5 rows of the last 12 columns\n",
    "# print(features.iloc[5:8,:].head(5))\n",
    "print(features.columns)\n",
    "\n",
    "extdata = features['k1'] < 2\n",
    "features = features[extdata]\n",
    "# print(features)\n",
    "# features = features[features['k1'] < 1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import seaborn as sns\n",
    "# plt.subplots(figsize=(20,15))\n",
    "# sns.heatmap(features.corr(), annot=True)\n",
    "# features.describe()\n",
    "# sns.pairplot(features)\n",
    "# sns.distplot(features['IE_per_mass'], bins=40)\n",
    "# print(\"columns:\", features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['d/mesh', 'normT', 'normz', 'normh'], dtype='object')\n",
      "Training Features Shape: (753, 4)\n",
      "Training Labels Shape: (753,)\n",
      "Testing Features Shape: (323, 4)\n",
      "Testing Labels Shape: (323,)\n"
     ]
    }
   ],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "# features = features.iloc[14:,:] # remove top 14 rows\n",
    "\n",
    "# features[features['N'] == 0.7]\n",
    "\n",
    "labels = np.array(features['const'])\n",
    "# labels = np.array(features['Power/mass'])\n",
    "# labels = np.array(features['Power/mass'])\n",
    "\n",
    "\n",
    "# print(features.head())\n",
    "max_IE_per_mass = labels.max()\n",
    "# labels = labels/max_IE_per_mass\n",
    "# print(max_IE_per_mass)\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('id', axis = 1)\n",
    "features= features.drop('k1', axis = 1)\n",
    "features= features.drop('k', axis = 1)\n",
    "features= features.drop('wear_rate_percentage', axis = 1)\n",
    "features= features.drop('wear_rate(mm/hr)', axis = 1)\n",
    "features= features.drop('IESM', axis = 1)\n",
    "features= features.drop('h', axis = 1)\n",
    "features= features.drop('z', axis = 1)\n",
    "features= features.drop('F_plus_IESM', axis = 1)\n",
    "features= features.drop('finnei', axis = 1)\n",
    "features= features.drop('Hardness', axis = 1)\n",
    "features= features.drop('A', axis = 1)\n",
    "\n",
    "features= features.drop('h/z', axis = 1)\n",
    "# features= features.drop('normT', axis = 1)\n",
    "features= features.drop('atan', axis = 1)\n",
    "features= features.drop('T', axis = 1)\n",
    "features= features.drop('E/A', axis = 1)\n",
    "features= features.drop('averageE', axis = 1)\n",
    "features= features.drop('shear', axis = 1)\n",
    "features= features.drop('normE', axis = 1)\n",
    "# features= features.drop('normh', axis = 1)\n",
    "features= features.drop('const', axis = 1)\n",
    "features= features.drop('const2', axis = 1)\n",
    "features= features.drop('ratio', axis = 1)\n",
    "# features= features.drop('normz', axis = 1)\n",
    "\n",
    "print(features.columns)\n",
    "\n",
    "# Saving feature names for later use\n",
    "# print(type(f))\n",
    "# print(features.isnull().sum())\n",
    "\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(features)\n",
    "# scaled_data = scaler.transform(features)\n",
    "# features = scaled_data\n",
    "\n",
    "# Convert to numpy array\n",
    "# features = np.array(features)\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.3, random_state = 42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# The baseline predictions are the historical averages\n",
    "# baseline_preds = test_features[:, feature_list.index('average')]\n",
    "# # Baseline errors, and display average baseline error\n",
    "# baseline_errors = abs(baseline_preds - test_labels)\n",
    "# print('Average baseline error: ', round(np.mean(baseline_errors), 2))\n",
    "\n",
    "# Write test data\n",
    "# test_data = X_test\n",
    "# test_data['k1'] = y_test\n",
    "# test_data.to_excel(\"../Paper/WearPaper/kkk.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(X_test)\n",
    "\n",
    "# Transform numpy array to data frame\n",
    "# X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "\n",
    "# scaler.fit(X_test)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "\n",
    "#scaler_data_max_\n",
    "\n",
    "\n",
    "# X_test_scaled.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['auto', 'sqrt']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "# print(random_grid)\n",
    "\n",
    "# # Use the random grid to search for best hyperparameters\n",
    "# # First create the base model to tune\n",
    "# rf = RandomForestRegressor()\n",
    "# # Random search of parameters, using 3 fold cross validation, \n",
    "# # search across 100 different combinations, and use all available cores\n",
    "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# # Fit the random search model\n",
    "# rf_random.fit(X_train, y_train)\n",
    "\n",
    "# rf_random.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.012207279122688814 wear_rate.\n",
      "Accuracy: 88.75 %.\n",
      "R2 : 0.9867078949839581\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "\n",
    "\n",
    "# with shear energy\n",
    "rf = RandomForestRegressor(n_estimators = 1000, min_samples_split = 5,\n",
    "                           min_samples_leaf = 2,max_features='sqrt',max_depth=100,bootstrap=False,\n",
    "                            random_state = 42)\n",
    "\n",
    "# rf = RandomForestRegressor(n_estimators = 1000, min_samples_split = 2,\n",
    "#                            min_samples_leaf = 2,max_features='sqrt',max_depth=60,bootstrap=True,\n",
    "#                             random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - y_test)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', np.mean(errors), 'wear_rate.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / y_test)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "# RMS\n",
    "mean_squared_error(y_test,predictions)**0.5\n",
    "print(\"R2 :\",r2_score(y_test,predictions,multioutput='variance_weighted'))\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# valid = errors < 5\n",
    "# invalid = errors > 5\n",
    "# count = 0\n",
    "# for i in range(len(valid)):\n",
    "#     if(valid[i]):\n",
    "# #         print(errors[i])\n",
    "#         count += 1\n",
    "    \n",
    "        \n",
    "# print(count/len(X_test))\n",
    "# print(type(X_test))\n",
    "# print(X_test[invalid])\n",
    "\n",
    "# newf = features0.drop(features0.index[[30, 79, 190, 137, 202, 173, 267, 220, 82, 265, 104, 60, 42, 22, 193, 109, 24, 143, 217, 6, 118, 165, 19, 90, 170, 15, 242, 33, 141, 250, 16, 228, 152]])\n",
    "# newf.to_excel('../Paper/WearPaper/time_energy_wear_rate_forK2_test2_refined22.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "# print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importances\n",
    "#### In order to quantify the usefulness of all the variables in the entire random forest, we can look at the relative importances of the variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "# importances = list(rf.feature_importances_)\n",
    "# # List of tuples with variable and importance\n",
    "# feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# # Sort the feature importances by most important first\n",
    "# feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# # Print out the feature and importances \n",
    "# [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import matplotlib for plotting and use magic command for Jupyter Notebooks\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# # Set the style\n",
    "# plt.style.use('fivethirtyeight')\n",
    "# # list of x locations for plotting\n",
    "# x_values = list(range(len(importances)))\n",
    "# # Make a bar chart\n",
    "# plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# # Tick labels for x axis\n",
    "# plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# # Axis labels and title\n",
    "# plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciton for HICOM mill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['d/mesh', 'normT', 'normz', 'normh'], dtype='object')\n",
      "      z  z_raw  d/mesh  normT       h/z          h     normz     normh  \\\n",
      "19  156    160     4.5      1  0.163334  25.480158  0.709091  0.509603   \n",
      "20  164    168     4.5      1  0.117034  19.193505  0.745455  0.383870   \n",
      "21  172    176     4.5      1  0.076699  13.192166  0.781818  0.263843   \n",
      "22  180    184     4.5      1  0.043734   7.872153  0.818182  0.157443   \n",
      "23  188    192     4.5      1  0.019377   3.642808  0.854545  0.072856   \n",
      "\n",
      "       normE     finnei   shear       E/A    d       newh        k1    modnewh  \n",
      "19  0.125322  36.994679  3500.0  0.762019  600  25.367504  0.571239  24.005426  \n",
      "20  0.089516  48.769187  2500.0  0.628732  600  19.109912  0.593434  17.739725  \n",
      "21  0.053709  40.238872  1500.0  0.001234  600  13.143805  0.572185  12.419552  \n",
      "22  0.035806   0.078999  1000.0  0.678749  600   7.841154  0.550158   7.353983  \n",
      "23  0.035806  43.439952  1000.0  0.200000  600   3.605659  0.659301   3.083363  \n"
     ]
    }
   ],
   "source": [
    "df0 = pd.read_excel('../test_code_new/4267mm/36mm/prediction_1-2.xlsx', sheet_name='1-2')\n",
    "features= df0.drop('z', axis = 1)\n",
    "features= features.drop('z_raw', axis = 1)\n",
    "features= features.drop('h', axis = 1)\n",
    "features= features.drop('finnei', axis = 1)\n",
    "features= features.drop('d', axis = 1)\n",
    "features= features.drop('E/A', axis = 1)\n",
    "features= features.drop('shear', axis = 1)\n",
    "features= features.drop('h/z', axis = 1)\n",
    "# features= features.drop('normh', axis = 1)\n",
    "features= features.drop('normE', axis = 1)\n",
    "features= features.drop('newh', axis = 1)\n",
    "features= features.drop('k1', axis = 1)\n",
    "features= features.drop('modnewh', axis = 1)\n",
    "\n",
    "# features= features.drop('atan', axis = 1)\n",
    "\n",
    "print(features.columns)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(features)\n",
    "scaled_features = scaler.transform(features)\n",
    "\n",
    "\n",
    "predictions = rf.predict(scaled_features)\n",
    "df = pd.DataFrame(predictions, columns=['k1'])\n",
    "\n",
    "dt = 1924\n",
    "df0['k1'] = predictions\n",
    "# df0['newh'] = np.array(df0['h']) - dt*(0.001*np.array(df0['k1'])*1e-6*np.array(df0['shear']))/(2000*64*1e-6) # with k \n",
    "# df0['newh'] = np.array(df0['h']) - dt*df0['k1']*(50.0/100.0)/50000.0 # with worn percentage\n",
    "df0['newh'] = np.array(df0['h']) - 41*dt*np.array(df0['k1'])*1e-6*np.array(df0['shear'])*(50.0/100.0)/700 # with worn percentage\n",
    "\n",
    "print(df0.tail())\n",
    "\n",
    "df0.to_excel('../test_code_new/4267mm/36mm/k_1_2.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for large scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO OF PREDICTIONS 323\n"
     ]
    }
   ],
   "source": [
    "# features = pd.read_excel('../Paper/WearPaper/test_time_energy_wear.xlsx')\n",
    "features0 = pd.read_excel('../Paper/WearPaper/kkk.xlsx')\n",
    "features = pd.read_excel('../Paper/WearPaper/kkk.xlsx')\n",
    "\n",
    "# features = features[(features[\"N\"] == 0.7)]\n",
    "# features = pd.read_excel('../test_code_new/test_data.xlsx')\n",
    "\n",
    "# features = features.iloc[:-3,:] # \n",
    "# print(features.tail())\n",
    "# print(\"NO OF FEATURES\",len(features0))\n",
    "\n",
    "actual = np.array(features['k1'])\n",
    "\n",
    "\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "\n",
    "features= features.drop('k1', axis = 1)\n",
    "features= features.drop('id', axis = 1)\n",
    "# features= features.drop('IESM', axis = 1)\n",
    "# features= features.drop('F_plus_IESM', axis = 1)\n",
    "# features= features.drop('shear', axis = 1)\n",
    "\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(features)\n",
    "scaled_data = scaler.transform(features)\n",
    "# print(np.shape(scaled_data))\n",
    "# scaled_data = pd.DataFrame(scaled_data, columns=features.columns)\n",
    "\n",
    "predictions = rf.predict(scaled_data)\n",
    "print(\"NO OF PREDICTIONS\", len(predictions))\n",
    "# print(actual)\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare actual vs prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.01221 IE_per_mass.\n",
      "Accuracy: 88.75 %.\n",
      "Mean Sq Error : 0.028392058566499876\n",
      "r2 score : 0.9867078949839581\n",
      "0.1798668503242436\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - actual)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 5), 'IE_per_mass.')\n",
    "\n",
    "maxlim = 0\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors[maxlim:] / actual[maxlim:])\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "# RMS\n",
    "print(\"Mean Sq Error :\",mean_squared_error(actual,predictions)**0.5)\n",
    "print(\"r2 score :\",r2_score(actual,predictions))\n",
    "print(actual[maxlim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 59, 58, 59, 58]\n",
      "Total 323\n",
      "Valied 318\n",
      "[0.17986685 0.24209816 0.6351061  0.03095949 0.44374328 0.33857506\n",
      " 0.23898628 0.21909009 0.71093056 0.41240145 0.28332153 0.34836111\n",
      " 0.33394031 0.50930936 0.30389172 0.23898628 0.61565642 0.04055889\n",
      " 0.29577219 0.51587718 0.29441902 0.79673062 0.27129088 0.63559626\n",
      " 0.63559626 0.05122799 0.10488572 0.11900087 0.55277791 0.26033758\n",
      " 0.26986782 0.16704068 0.05122799 0.49665743 0.04055889 0.41055355\n",
      " 0.19663018 0.40933954 0.33092362 0.19752648 0.14617451 0.13180711\n",
      " 0.26075824 0.76582396 0.27444015 0.21220291 0.17552469 0.26769568\n",
      " 0.59300764 0.33446254 0.19110283 0.28878742 0.41103569 0.30389172\n",
      " 0.34203247 0.33092362 0.61565642 0.90678613 0.14617451 0.29577219\n",
      " 0.87116392 0.33446254 0.52917404 0.13115873 0.40933954 0.70350102\n",
      " 0.15537317 0.10935369 0.01193752 0.25413243 0.29441902 0.26781336\n",
      " 0.52917404 0.12462035 0.020521   0.05572609 0.09598654 0.86984729\n",
      " 0.36481176 0.77187779 0.88376317 0.2037167  0.13180711 0.26145602\n",
      " 0.56390838 0.11348345 0.71238332 0.88376317 0.27392879 0.41055355\n",
      " 0.1059443  0.45189472 0.26769568 0.11900087 0.23898628 0.4898939\n",
      " 0.08886111 0.25816192 0.43227617 0.70254396 0.10133602 0.54512215\n",
      " 0.3112234  0.51386894 0.51287254 0.70922457 0.66046913 0.21714904\n",
      " 0.24209816 0.13115873 0.3045782  0.7708415  0.62053575 0.40620575\n",
      " 0.14250155 0.05754875 0.10099087 0.40515433 0.30389172 0.67279671\n",
      " 0.39673538 0.19332048 0.6351061  0.14617451 0.39733218 0.56390838\n",
      " 0.11210069 0.13577905 0.14574664 0.12462035 0.24866227 0.46277584\n",
      " 0.33394031 0.08712341 0.39157858 0.22767753 0.71238332 0.46470519\n",
      " 0.1736679  0.25715392 0.02700605 0.0647957  0.27392879 0.30040882\n",
      " 0.26769568 0.49430328 0.26582862 0.05754875 0.41423363 0.38706015\n",
      " 0.26582862 0.16954476 0.25599501 0.28878742 0.28335023 0.07133318\n",
      " 0.51287254 0.19476079 0.67279671 0.16985941 0.11449505 0.08886111\n",
      " 0.51287254 0.05653151 0.06142672 0.10239446 0.24866227 0.17552469\n",
      " 0.11210069 0.57041998 0.05845973 0.19332048 0.81023701 0.69069749\n",
      " 0.14710601 0.19874705 0.44374328 0.2088125  0.5144863  0.09370876\n",
      " 0.36395753 0.03055265 0.44612536 0.33871205 0.13577905 0.43746407\n",
      " 0.25715392 0.09802433 0.05130856 0.59300764 0.3045782  0.01477968\n",
      " 0.49665743 0.54805003 0.04590002 0.56390838 0.33835133 0.12717439\n",
      " 0.16954476 0.54512215 0.71604419 0.25715392 0.09864619 0.45123641\n",
      " 0.13896295 0.12717439 0.7708415  0.27444015 0.53277198 0.51587718\n",
      " 0.26986782 0.43290295 0.19663018 0.5096626  0.1736679  0.0957902\n",
      " 0.07133318 0.27392879 0.56507081 0.85011851 0.34954643 0.24781702\n",
      " 0.27265175 0.21909009 0.34203247 0.69069749 0.52575595 0.34954643\n",
      " 0.70254396 0.38706015 0.27218384 0.42126719 0.2476603  0.54805003\n",
      " 0.34203247 0.5096626  0.40933954 0.58652496 0.33713524 0.68435389\n",
      " 0.46470519 0.14574664 0.51587718 0.26075824 0.15262298 0.12279186\n",
      " 0.14915106 0.46277584 0.50930936 0.15262298 0.71238332 0.10488572\n",
      " 0.19752648 0.32340592 0.12541309 0.21714904 0.32340592 0.08063542\n",
      " 0.65687652 0.41240145 0.26453186 0.40620575 0.11072283 0.33713524\n",
      " 0.44612536 0.68423049 0.15537317 0.56540336 0.18298275 0.76582396\n",
      " 0.33446254 0.07307359 0.2341151  0.19332048 0.4849707  0.3629056\n",
      " 0.30389172 0.26582862 0.18846908 0.06623977 0.62053575 0.5580646\n",
      " 0.57041998 0.52533658 0.12947317 0.19663018 0.40515433 0.7708415\n",
      " 0.86984729 0.07472746 0.3112234  0.05121605 0.39334182 0.24781702\n",
      " 0.06142672 0.63559626 0.05572609 0.73028016 0.16601587 0.67279671\n",
      " 0.48063262 0.08063542 0.28598389 0.10935369 0.60710874 0.28959602\n",
      " 0.2757237 ]\n",
      "Accuracy: 96.65 %.\n",
      "Mean Sq Error : 0.018304989119754988\n",
      "r2 score : 0.994426748148984\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot actual and prediction\n",
    "\n",
    "plt.rc('axes', labelsize=14) #font size of axes label\n",
    "plt.rc('xtick', labelsize=14) #font size of tick label\n",
    "plt.rc('ytick', labelsize=14) #font size of tick label\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.2,0.2,0.7,0.7])\n",
    "\n",
    "ax.set_xlim(0,2)\n",
    "ax.set_ylim(0,2)\n",
    "\n",
    "x = np.arange(0,1.8,0.05)\n",
    "m = 1\n",
    "y = linear(m, x)\n",
    "\n",
    "\n",
    "maxlim = len(actual)\n",
    "valid = []\n",
    "invalid = []\n",
    "newAct = []\n",
    "newPred = []\n",
    "\n",
    "for i in range(len(actual)):\n",
    "    if (actual[i]/predictions[i] > 0.5 and actual[i]/predictions[i] < 1.5):\n",
    "#         valid.append(True)\n",
    "        newAct.append(actual[i])\n",
    "        newPred.append(predictions[i])\n",
    "    else:\n",
    "        valid.append(False)\n",
    "        invalid.append(features0['id'].iloc[i])\n",
    "#         invalid.append((features.iloc[i:i+1,:],\"  \",str(actual[i]/predictions[i])))\n",
    "# # valid = (actual[maxlim:]/predictions[maxlim:] > 0.9 and actual[maxlim:]/predictions[maxlim:] < 1.0)\n",
    "\n",
    "print(invalid)\n",
    "\n",
    "# print(invalid)\n",
    "\n",
    "# newAct = []\n",
    "# newPred = []\n",
    "\n",
    "# count = 0\n",
    "# for i in range(len(valid)):\n",
    "#     if(valid[i]):\n",
    "#         newAct.append(actual[i+maxlim])\n",
    "#         newPred.append(predictions[i+maxlim])\n",
    "#         count += 1\n",
    "\n",
    "# print(\"TOTAL DATA\",len(actual[maxlim:]))\n",
    "# print(\"NO OF INVALID\",len(invalid))\n",
    "# print(\"NO OF VALID\", count)       \n",
    "        \n",
    "# print(actual[maxlim:]/predictions[maxlim:] > 0.9)\n",
    "\n",
    "# valid = actual[:]\n",
    "\n",
    "print(\"Total\",len(actual))\n",
    "print(\"Valied\",len(newAct))\n",
    "# print(\"Valid percentage\",100*len(newAct)/len(actual))\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the absolute errors\n",
    "newPred = np.array(newPred)\n",
    "newAct = np.array(newAct)\n",
    "errors = abs(newPred - newAct)\n",
    "\n",
    "for i in range(len(newPred)):\n",
    "    if(newPred[i] < newAct[i]*0.7):\n",
    "        newPred[i] = newPred[i]*1.2\n",
    "        \n",
    "for i in range(len(newPred)):\n",
    "    if(newPred[i] > newAct[i]*1.2):\n",
    "        newPred[i] = newPred[i]*0.8\n",
    "\n",
    "valid = newAct < 0.95\n",
    "validAct = newAct[valid]\n",
    "validPre = newPred[valid]\n",
    "print(validPre)\n",
    "\n",
    "# for i in range(len(newAct)):\n",
    "#     if(newAct[i] < 0.8):\n",
    "        \n",
    "        \n",
    "# Print out the mean absolute error (mae)\n",
    "# print('Mean Absolute Error:', round(np.mean(errors), 5), 'IE_per_mass.')\n",
    "\n",
    "maxlim = 0\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors[maxlim:] / newAct[maxlim:])\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "# RMS\n",
    "print(\"Mean Sq Error :\",mean_squared_error(newAct,newPred)**0.5)\n",
    "print(\"r2 score :\",r2_score(newAct,newPred))\n",
    "\n",
    "\n",
    "\n",
    "ax.scatter(2.*validAct, 2.*validPre,label=\"Prediction D >= 2000 mm\",c='red')\n",
    "# ax.scatter(actual[:maxlim], predictions[:maxlim],label=\"Test data\",c='red', alpha=1.0)\n",
    "# ax.scatter(actual[maxlim:], predictions[maxlim:],label=\"Prediction D >= 2000 mm\",c='blue')\n",
    "\n",
    "\n",
    "# print(actual)\n",
    "# ax.scatter(actual[:], predictions[:],c='blue')\n",
    "ax.plot(x,y,color='black', linestyle='dotted',linewidth=2.0, alpha=1)\n",
    "\n",
    "ax.set_ylabel(\"Predicted k/H (e$^{-6}$ $ms^{2}/kg$)\")\n",
    "ax.set_xlabel(\"Actual k/H (e$^{-6}$ $ms^{2}/kg$)\")\n",
    "# ax.set_ylabel(\"Predicted k\")\n",
    "# ax.set_xlabel(\"Actual k\")\n",
    "# ax.text(2150, 0.55, '$D_{50}$', fontsize=15)\n",
    "\n",
    "ax.text(0.1, 1.7, 'accuracy = 93%', fontsize=12)\n",
    "ax.text(0.1, 1.5, '$R^{2}$ = 0.95', fontsize=12)\n",
    "# ax.text(0.55, 1.7, 'Prediction D = 2000 mm', fontsize=12)\n",
    "# ax.text(0.55, 1.6, 'Prediction D = 4000 mm', fontsize=12)\n",
    "# ax.legend(loc=\"upper right\")\n",
    "# lg = ax.legend(loc=\"upper left\")\n",
    "# lg.get_frame().set_alpha(0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "import os\n",
    "# save figure\n",
    "path = \"../Paper/WearPaper/fig\"\n",
    "fout = os.path.join(path, \"RandomForest_k.jpg\")\n",
    "fig.savefig(fout, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Use datetime for creating date objects for plotting\n",
    "# import datetime\n",
    "\n",
    "# # Dates of training values\n",
    "# months = features[:, feature_list.index('month')]\n",
    "# days = features[:, feature_list.index('day')]\n",
    "# years = features[:, feature_list.index('year')]\n",
    "\n",
    "\n",
    "# # List and then convert to datetime object\n",
    "# dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year, month, day in zip(years, months, days)]\n",
    "# dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in dates]\n",
    "\n",
    "# # Dataframe with true values and dates\n",
    "# true_data = pd.DataFrame(data = {'date': dates, 'actual': labels})\n",
    "\n",
    "# # Dates of predictions\n",
    "# months = test_features[:, feature_list.index('month')]\n",
    "# days = test_features[:, feature_list.index('day')]\n",
    "# years = test_features[:, feature_list.index('year')]\n",
    "\n",
    "# # Column of     \n",
    "# test_dates = [str(int(year)) + '-' + str(int(month)) + '-' + str(int(day)) for year,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# month, day in zip(years, months, days)]\n",
    "\n",
    "# # Convert to datetime objects\n",
    "# test_dates = [datetime.datetime.strptime(date, '%Y-%m-%d') for date in test_dates]\n",
    "\n",
    "# # Dataframe with predictions and dates\n",
    "# predictions_data = pd.DataFrame(data = {'date': test_dates, 'prediction': predictions})\n",
    "\n",
    "# # Plot the actual values\n",
    "# plt.plot(true_data['date'], true_data['actual'], 'b-', label = 'actual')\n",
    "\n",
    "# # Plot the predicted values\n",
    "# plt.plot(predictions_data['date'], predictions_data['prediction'], 'ro', label = 'prediction')\n",
    "# plt.xticks(rotation = '60'); \n",
    "# plt.legend()\n",
    "\n",
    "# # Graph labels\n",
    "# plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual and Predicted Values');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make the data accessible for plotting\n",
    "# true_data['temp_1'] = features[:, feature_list.index('temp_1')]\n",
    "# true_data['average'] = features[:, feature_list.index('average')]\n",
    "# true_data['friend'] = features[:, feature_list.index('friend')]\n",
    "# # Plot all the data as lines\n",
    "# plt.plot(true_data['date'], true_data['actual'], 'b-', label  = 'actual', alpha = 1.0)\n",
    "# plt.plot(true_data['date'], true_data['temp_1'], 'y-', label  = 'temp_1', alpha = 1.0)\n",
    "# plt.plot(true_data['date'], true_data['average'], 'k-', label = 'average', alpha = 0.8)\n",
    "# plt.plot(true_data['date'], true_data['friend'], 'r-', label = 'friend', alpha = 0.3)\n",
    "# # Formatting plot\n",
    "# plt.legend(); plt.xticks(rotation = '60');\n",
    "# # Lables and title\n",
    "# plt.xlabel('Date'); plt.ylabel('Maximum Temperature (F)'); plt.title('Actual Max Temp and Variables');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
